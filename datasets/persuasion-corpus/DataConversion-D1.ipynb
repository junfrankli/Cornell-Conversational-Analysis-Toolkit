{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "os.chdir('/Users/grace/Cornell-Conversational-Analysis-Toolkit/')\n",
    "from convokit import Corpus, User, Utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'persuasion-corpus/role-bin.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1154d44fe96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/grace/Cornell-Conversational-Analysis-Toolkit/datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"persuasion-corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, utterances, utterance_start_index, utterance_end_index, merge_lines, exclude_utterance_meta, exclude_conversation_meta, exclude_user_meta, exclude_overall_meta, version)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"utterances-index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfield_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bin\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude_utterance_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-bin.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                             \u001b[0ml_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mut\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'persuasion-corpus/role-bin.p'"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir('/Users/grace/Cornell-Conversational-Analysis-Toolkit/datasets')\n",
    "corpus = Corpus(filename=\"persuasion-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/grace/PersuasionForGoodData/full_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = \"/Users/grace/PersuasionForGoodData/300_info.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full PersuasionForGood dataset contains two files:  <br>\n",
    "    full_info.csv <br>\n",
    "    full_dialog.csv <br>\n",
    "The metadata for each of the users are contained in the full_info.csv file. \n",
    "The first five columns of each line include information about the dialogue that the user is a part of. Because a user can be involved in multiple dialogues, each dialogue is a key within the user metadata which retreives the role, donation amount and number of turn associated with the user within a specific dialogue. The rest of the entries correspond to the 23 dimensional feature vector associated with each user. \n",
    "\n",
    "Additionally, the dictionary diag_to_user is used so that the users can be searched with just a dialogue ID and role. This is because the full_dialog.csv file only has the dialogue id and not the user_ids of the participating users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "user_meta = defaultdict(dict)\n",
    "first = True\n",
    "headers = None\n",
    "diag_to_user = {}\n",
    "diag_meta = {}\n",
    "roles = [\"persuader\",\"persuadee\"]\n",
    "with open(data_dir, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:          \n",
    "        info = line.split(\",\")\n",
    "        if first:\n",
    "            #Getting the headers of the personality vector\n",
    "            headers = info[5:]\n",
    "            first = False\n",
    "        else:\n",
    "            diag_to_user[(info[0],info[2])] = info[1]\n",
    "            if info[0] in diag_meta:\n",
    "                diag_meta[info[0]][roles[int(info[2])]] = info[1]\n",
    "            else:\n",
    "                diag_meta[info[0]] = {\"donation_amt\": info[3],\n",
    "                                      \"num_turns\": info[4],\n",
    "                                      \"intended_amt\": None}\n",
    "                diag_meta[info[0]][roles[int(info[2])]] = info[1]\n",
    "            if info[1] not in user_meta:\n",
    "                for i, heading in enumerate(headers):\n",
    "                    user_meta[info[1]][heading] = info[i+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180717-200206_41_live</td>\n",
       "      <td>A3JLE2LJ5I17E2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180719-120436_413_live</td>\n",
       "      <td>AU7A3QNJF3O00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180719-120436_413_live</td>\n",
       "      <td>A5NE8TWS8ZV7B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180719-122534_38_live</td>\n",
       "      <td>A125KW9P18V5Z1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20180719-122534_38_live</td>\n",
       "      <td>A2T007HZK66WM</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         B2              B3  B4   B5   B6    B7\n",
       "1   20180717-200206_41_live  A3JLE2LJ5I17E2   1  0.5  0.5  10.0\n",
       "2  20180719-120436_413_live   AU7A3QNJF3O00   0  NaN  0.0  10.0\n",
       "3  20180719-120436_413_live   A5NE8TWS8ZV7B   1  NaN  0.0  10.0\n",
       "4   20180719-122534_38_live  A125KW9P18V5Z1   0  NaN  0.0  11.0\n",
       "5   20180719-122534_38_live   A2T007HZK66WM   1  5.0  0.5  11.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "anno_info = pd.read_excel(anno_dir) \n",
    "anno_info.loc[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in anno_info.values:          \n",
    "    if line[2] == 1:\n",
    "        diag_meta[info[0]][\"intended_amt\"] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_users = {k: User(name = k, meta = v) for k,v in user_meta.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 1285\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users in the data = {0}\".format(len(corpus_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Utterances\n",
    "\n",
    "Utterances can be found in the full_dialog.csv, with 20932 lines total. The raw data has four columns: <br>\n",
    "\"Unit\" is the text of the utterance.  <br>\n",
    "\"Turn\" is the turn of the utterance; for example, the first back and forth between persuader and persuadee would both have \"Turn\" = 0.  <br>\n",
    "\"B2\" is the conversation ID. <br>\n",
    "\"B4\" is the role of the user in this utterance, persuader(0) or persuadee (1). <br>\n",
    "\n",
    "As per the utterance object, we give each utterance a unique id and the unique user ID is found using a dictionary which takes in the conversation ID and role of user. The metadata for each utterance includes both the turn and role  of user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Turn</th>\n",
       "      <th>B4</th>\n",
       "      <th>B2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi. I am doing good. How about you?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm doing pretty good for a Tuesday morning.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Haha. Same here, but it really feels like a Mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ugh yes it does!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I can not believe how warm it is already.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Unit  Turn  B4  \\\n",
       "1           1                Hi. I am doing good. How about you?     0   1   \n",
       "2           2      I'm doing pretty good for a Tuesday morning.      1   0   \n",
       "3           3  Haha. Same here, but it really feels like a Mo...     1   1   \n",
       "4           4                                   Ugh yes it does!     2   0   \n",
       "5           5          I can not believe how warm it is already.     2   1   \n",
       "\n",
       "                         B2  \n",
       "1  20180904-045349_715_live  \n",
       "2  20180904-045349_715_live  \n",
       "3  20180904-045349_715_live  \n",
       "4  20180904-045349_715_live  \n",
       "5  20180904-045349_715_live  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "utterance_data = pd.read_csv(\"/Users/grace/PersuasionForGoodData/full_dialog.csv\") \n",
    "utterance_data.loc[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diag_to_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_corpus = {}\n",
    "convo_order = utterance_data[\"Unnamed: 0\"]\n",
    "dia_to_id = {}\n",
    "\n",
    "for i in list(range(len(utterance_data))):\n",
    "    utterance_data_line = utterance_data.loc[i, :]\n",
    "    B2 = utterance_data_line[\"B2\"]\n",
    "    B4 = utterance_data_line[\"B4\"]\n",
    "    Text = utterance_data_line[\"Unit\"]\n",
    "    meta = {\"role\": B4, \"turn_index\": utterance_data_line[\"Turn\"], \"dialogue_id\" : B2, \"er_label_1\": None, \"ee_label_1\": None, \"er_label_2\": None, \"er_label_2\": None,\"neg\": None, \"neu\": None, \"pos\": None}\n",
    "    \n",
    "    if utterance_data_line[\"Unnamed: 0\"] == 0:\n",
    "        ReplyTo = None\n",
    "    else:  \n",
    "        ReplyTo = i - 1\n",
    "    if utterance_data_line[\"Unnamed: 0\"] == 0:\n",
    "        Root = i\n",
    "    else:\n",
    "        utter_id = list(range(0, i+1))\n",
    "        convo_order_sub = convo_order.loc[0:i]\n",
    "        df = pd.DataFrame({\"utter_id\": utter_id, \"convo_order_sub\":convo_order_sub})\n",
    "        df2 = df[df[\"convo_order_sub\"] == 0]\n",
    "        Root = df2['utter_id'].max()\n",
    "    utterance_corpus[i] = Utterance(i, corpus_users[diag_to_user[(B2,str(B4))]], Root, ReplyTo, None, Text, meta=meta)\n",
    "    dia_to_id[(B2,B4,utterance_data_line[\"Turn\"])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 0,\n",
       " 'turn_index': 0,\n",
       " 'dialogue_id': '20180904-045349_715_live',\n",
       " 'er_label_1': None,\n",
       " 'ee_label_1': None,\n",
       " 'er_label_2': None,\n",
       " 'neg': None,\n",
       " 'neu': None,\n",
       " 'pos': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_corpus[0].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_utterances = pd.read_excel(\"/Users/grace/PersuasionForGoodData/300_dialog.xlsx\") \n",
    "anno_utterances.values[pd.isna(anno_utterances.values)] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in anno_utterances.values:\n",
    "    if not pd.isna(line[4]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"er_label_1\"] = line[4]\n",
    "    if not pd.isna(line[5]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"e2_label_1\"] = line[5]\n",
    "    if not pd.isna(line[6]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"er_label_2\"] = line[6]\n",
    "    if not pd.isna(line[7]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"ee_label_2\"] = line[7]\n",
    "    if not pd.isna(line[8]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"neg\"] = line[8]\n",
    "    if not pd.isna(line[9]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"neu\"] = line[9]\n",
    "    if not pd.isna(line[10]):\n",
    "        utterance_corpus[dia_to_id[(line[0],line[1],line[2])]].meta[\"pos\"] = line[10]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating corpus from utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_list = [utterance for k, utterance in utterance_corpus.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion_corpus = Corpus(utterances=utterance_list, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the dataset = 1017\n"
     ]
    }
   ],
   "source": [
    "print(\"number of conversations in the dataset = {}\".format(len(persuasion_corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample conversation 0:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "sample conversation 1:\n",
      "[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "sample conversation 2:\n",
      "[41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "sample conversation 3:\n",
      "[61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
      "sample conversation 4:\n",
      "[82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]\n"
     ]
    }
   ],
   "source": [
    "convo_ids = persuasion_corpus.get_conversation_ids()\n",
    "for i, convo_idx in enumerate(convo_ids[0:5]):\n",
    "    print(\"sample conversation {}:\".format(i))\n",
    "    print(persuasion_corpus.get_conversation(convo_idx).get_utterance_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation in persuasion_corpus.conversations.values():\n",
    "    conversation.meta = diag_meta[conversation.get_utterance(conversation._utterance_ids[0]).meta['dialogue_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persuasion_corpus.dump(\"persuasion_corpus\",\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x1a1c354080>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D1 Summary Stats\n",
    "\n",
    "Summary statistics (number of dialogues and participants) as well as replicating some stats from Table 2 of paper to demonstrate integrity of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dialogues in Table 2, matches\n",
    "len(persuasion_corpus.get_conversation_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Participants in Table 2, matches\n",
    "len(persuasion_corpus.all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "donations = []\n",
    "turns = []\n",
    "allconvoids = persuasion_corpus.get_conversation_ids()\n",
    "for i in list(range(0, len(allconvoids))):\n",
    "    convo_id = allconvoids[i]\n",
    "    temp = persuasion_corpus.get_conversation(convo_id).meta[\"donation_amt\"]\n",
    "    convo_turn = persuasion_corpus.get_conversation(convo_id).meta[\"num_turns\"]\n",
    "    donations.append(float(temp))\n",
    "    turns.append(float(convo_turn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(donations) #should be same as number of dialogues, matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean/Median/Min/Max of donation amounts and number of turns per conversation in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.429390363815142 0.0 0.0 500.0\n",
      "10.420845624385448 10.0 4.0 15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(donations), np.median(donations), min(donations), max(donations)) #average donation, doesn't match\n",
    "print(np.mean(turns), np.median(turns), min(turns), max(turns)) #average turns, matches paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "wordscount = []\n",
    "allwords = []\n",
    "allutterids = persuasion_corpus.get_utterance_ids()\n",
    "for i in list(range(0, len(allutterids))):\n",
    "    utter_id = allutterids[i]\n",
    "    text = persuasion_corpus.get_utterance(utter_id).text\n",
    "    words.append(text) #gives text of each utterance\n",
    "    #print(text.split())\n",
    "    wordscount.append(len(text.split())) #gives word count of each utterance\n",
    "    allwords = allwords + text.split() #adds utterance words to a list of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.804844257596024 13.0 1 100\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(wordscount), np.median(wordscount), min(wordscount), max(wordscount)) #avg words per utterance, does not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351759"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17162"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(allwords)) #total unique tokens, does not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion_corpus.get_utterance(2).meta[\"role\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuadee_words = []\n",
    "persuader_words = []\n",
    "for i in list(range(0, len(allutterids))):\n",
    "    utter_id = allutterids[i]\n",
    "    role = persuasion_corpus.get_utterance(utter_id).meta[\"role\"]\n",
    "    text = persuasion_corpus.get_utterance(utter_id).text\n",
    "    if role == 1:\n",
    "        persuadee_words.append(len(text.split()))\n",
    "    if role == 0:\n",
    "        persuader_words.append(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.470286488579172 10.0 1 98\n",
      "20.05509433962264 16.0 1 100\n"
     ]
    }
   ],
   "source": [
    "#average words per utterance for persuadee, does not match\n",
    "print(np.mean(persuadee_words), np.median(persuadee_words), min(persuadee_words), max(persuadee_words))\n",
    "#average words per utterance for persuader, does not match\n",
    "print(np.mean(persuader_words), np.median(persuader_words), min(persuader_words), max(persuader_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our statistics vs. Table 2 in Paper\n",
    "\n",
    "\n",
    "| Statistic     | In Paper        | Ours  | \n",
    "| :------------- |:-------------:| :-----:| \n",
    "| Dialogues  | 1017 | 1017 | \n",
    "| Participants | 1285  |  1285 |\n",
    "| Avg Donation | \\$0.35 | $2.43 |\n",
    "| Avg Turns Per Dialogue  | 10.43 | 10.43 |\n",
    "| Avg Words Per Utterance  | 19.36 | 16.80 |\n",
    "| Total Unique Tokens (words?) | 8141  |  17162 |\n",
    "| Avg Words Per Utterance (Persuadee)  | 15.65 | 13.47 |\n",
    "| Avg Words Per Utterance (Persuader)  | 22.96 | 20.06 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
